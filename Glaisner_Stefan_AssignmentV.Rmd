---
title: 'Assignment V: GitHub and the ticketmaster.com API'
subtitle: 'Data Science Project Management | Winter Term 2021/22'
author: "Stefan Glaisner (4222790)"
date: "`r format(Sys.Date(), '%d-%m-%Y')`"
output:
  rmdformats::downcute:
    code_folding: hide
---

I hereby confirm that I worked on this Assignment entirely on my own and that my submission is in line with the *Code of Conduct* outlined on the lecture slides.


## 1. Setting up a new GitHub repository

After having registered on [GitHub](https://github.com), I initialized a new public repository for this assignment called [Assignment V GitHub and the ticketmaster.com API](https://github.com/stefan-1997/Assignment-V-GitHub-and-the-ticketmaster.com-API). For version control, I relied on the [Sourcetree GUI](https://www.sourcetreeapp.com/) for a convenient representation of the development history. To finally start over with the assignment, I cloned the Git repository to my local computer and pulled the latest version of the project (consisting of the *README.md* and the *.gitignore* file).


## 2. Getting to know the API

As a first step, I cleaned my environment and loaded the relevant packages.

```{r start, error = FALSE, warning = FALSE, message = FALSE}

rm(list = ls())

library(tidyverse)
library(httr)
library(jsonlite)
library(maps)

```

The documentation website for the API reveals that there is a limit of 5,000 API calls per day and an additional rate limitation of five requests per second. Thus, one would usually define an initial time limit of 0.2 seconds for API calls to not encounter any error messages on this behalf. However, while intensively working with the API, I noticed that with such a short time limit, errors with the status code 429 ('Too Many Requests') are likely to occur. Accordingly, I set the pause time somewhat higher.

Furthermore, I copied the API key provided by *ticketmaster.com* on their website to a separate R-script as it is usually done due to security reasons. Calling this specific script, the key is then easily integrated into the current environment. In order to replicate my results, one has to assign the copied API key to a variable called ``api_key`` in a separate script called *api_key_ticketmaster.R*.

```{r api_setup, error = FALSE, warning = FALSE, message = FALSE}

sleep <- 0.4

source("api_key_ticketmaster.R")

```


## 3. Interacting with the API - the basics

Based on the documentation on the website, I used the URL below in combination with restrictions on the parameters *countryCode* and *locale* to retrieve the desired data frame. The content ``json_parsed_search`` from the response object ``get_search_result`` consists of a lists of lists. The variables, which are relevant for this task, are stored in the data frame ``venues`` of the list object ``_embedded``. Since the data frame ``venues`` itself consists of multiple data frames, the focal variables have to be extracted specifically.

```{r venue_data_ex3, error = FALSE, warning = FALSE, message = FALSE}

get_search_result <- GET("https://app.ticketmaster.com/discovery/v2/venues.json",
                         query = list(apikey = api_key,
                                      countryCode = "DE",
                                      locale = "*"))

json_parsed_search <- fromJSON(content(get_search_result, as = "text"))
glimpse(json_parsed_search)

venue_data <- data.frame(
  name = json_parsed_search[["_embedded"]]$venues$name,
  city = json_parsed_search[["_embedded"]]$venues$city$name,
  postalCode = json_parsed_search[["_embedded"]]$venues$postalCode,
  address = json_parsed_search[["_embedded"]]$venues$address$line1,
  url = json_parsed_search[["_embedded"]]$venues$url,
  longitude = as.double(json_parsed_search[["_embedded"]]$venues$location$longitude),
  latitude = as.double(json_parsed_search[["_embedded"]]$venues$location$latitude)
  )

glimpse(venue_data)

```


## 4. Interacting with the API - advanced

As can be seen from the ``page`` content element, only the first 20 venues were retrieved from the API using the query from above. However, there are `r json_parsed_search[["page"]]$totalElements` cases in total spread over `r json_parsed_search[["page"]]$totalPages` different pages.

```{r n_pages, error = FALSE, warning = FALSE, message = FALSE}

json_parsed_search[["page"]]

```

As in [exercise 6]{#ex6} the same task has to be done for a second country, I decided to write a function ``ticketmaster_call`` which can then be easily applied to a country of choice. The function basically consists of an initial GET request that extracts general information about the venues contained in this specific API subset, which are then used to define the parameters of a ``for`` loop that runs through all the results pages. Since the last page is likely to contain less entries than the previous one, the information from this  page is extracted separately outside the loop.

``ticketmaster_call`` returns a list object containing the final data frame with the specified variables, a vector including the status codes of all GET requests and a list with some meta information such as the number of pages and cases. 

```{r function_ex4, error = FALSE, warning = FALSE, message = FALSE}

ticketmaster_call <- function(api_key, country_code){
  
  # initial call to retrieve general information about API parameters
  get_search_result <- GET("https://app.ticketmaster.com/discovery/v2/venues.json",
                           query = list(apikey = api_key,
                                        countryCode = country_code,
                                        locale = "*"))
  
  json_parsed_search <- fromJSON(content(get_search_result, as = "text"))
  
  n_pages <- json_parsed_search[["page"]]$totalPages  # total number of pages
  n_entries <- json_parsed_search[["page"]]$totalElements  # total number of cases
  per_page <- json_parsed_search[["page"]]$size  # cases per page
  
  last_page <- n_entries + per_page - n_pages*per_page  # number of cases at last page
  
  check_success <- rep(NA, n_pages)  # initialize vector that stores the status code of each GET request
  
  # initialize target data frame
  target_df <- data.frame(
      name = character(n_entries),
      city = character(n_entries),
      postalCode = character(n_entries),
      address = character(n_entries),
      url = character(n_entries),
      longitude = double(n_entries),
      latitude = double(n_entries)
      )
  
  # pause next GET request for some time to not exceed the time limit
  Sys.sleep(sleep)
  
  # looping over all complete pages
  for (i in 0:(n_pages-2)) {
    
    get_search_result_loop <- GET("https://app.ticketmaster.com/discovery/v2/venues.json",
                                  query = list(apikey = api_key,
                                               countryCode = country_code,
                                               locale = "*",
                                               page = i))
    
    check_success[(i+1)] <- get_search_result_loop[["status_code"]] # extract status code
    
    json_parsed_search_loop <- fromJSON(content(get_search_result_loop, as = "text"))
    
    # define row index
    row_number <- (per_page*(i+1) - (per_page-1)):(per_page*(i+1))
    
    if (!is.null(json_parsed_search_loop[["_embedded"]]$venues$name)) {
      
      target_df[row_number, 1] <- json_parsed_search_loop[["_embedded"]]$venues$name
      
    } else {
      
      target_df[row_number, 1] <- NA
      
    }
    
    if (!is.null(json_parsed_search_loop[["_embedded"]]$venues$city$name)) {
      
      target_df[row_number, 2] <- json_parsed_search_loop[["_embedded"]]$venues$city$name
      
    } else {
      
      target_df[row_number, 2] <- NA
      
    }
    
    if (!is.null(json_parsed_search_loop[["_embedded"]]$venues$postalCode)) {
      
      target_df[row_number, 3] <- json_parsed_search_loop[["_embedded"]]$venues$postalCode
      
    } else {
      
      target_df[row_number, 3] <- NA
      
    }
    
    if (!is.null(json_parsed_search_loop[["_embedded"]]$venues$address$line1)) {
      
      target_df[row_number, 4] <- json_parsed_search_loop[["_embedded"]]$venues$address$line1
      
    } else {
      
      target_df[row_number, 4] <- NA
      
    }
    
    if (!is.null(json_parsed_search_loop[["_embedded"]]$venues$url)) {
      
      target_df[row_number, 5] <- json_parsed_search_loop[["_embedded"]]$venues$url
      
    } else {
      
      target_df[row_number, 5] <- NA
      
    }
    
    if (!is.null(json_parsed_search_loop[["_embedded"]]$venues$location$longitude)) {
      
      target_df[row_number, 6] <- as.double(json_parsed_search_loop[["_embedded"]]$venues$location$longitude)
      
    } else {
      
      target_df[row_number, 6] <- NA
      
    }
    
    if (!is.null(json_parsed_search_loop[["_embedded"]]$venues$location$latitude)) {
      
      target_df[row_number, 7] <- as.double(json_parsed_search_loop[["_embedded"]]$venues$location$latitude)
      
    } else {
      
      target_df[row_number, 7] <- NA
      
    }
    
    Sys.sleep(sleep)
  
  }
  
  # retrieve findings from last page
  get_search_result_last <- GET("https://app.ticketmaster.com/discovery/v2/venues.json",
                                  query = list(apikey = api_key,
                                               countryCode = country_code,
                                               locale = "*",
                                               page = (n_pages-1)))
  
  check_success[n_pages] <- get_search_result_loop[["status_code"]] # extract status code
  
  json_parsed_search_last <- fromJSON(content(get_search_result_last, as = "text"))
    
  row_number_last <- (n_entries - last_page + 1):n_entries
  
  if (!is.null(json_parsed_search_last[["_embedded"]]$venues$name)) {
    
    target_df[row_number_last, 1] <- json_parsed_search_last[["_embedded"]]$venues$name
    
  } else {
    
    target_df[row_number_last, 1] <- NA
    
  }
  
  if (!is.null(json_parsed_search_last[["_embedded"]]$venues$city$name)) {
    
    target_df[row_number_last, 2] <- json_parsed_search_last[["_embedded"]]$venues$city$name
    
  } else {
    
    target_df[row_number_last, 2] <- NA
    
  }
  
  if (!is.null(json_parsed_search_last[["_embedded"]]$venues$postalCode)) {
    
    target_df[row_number_last, 3] <- json_parsed_search_last[["_embedded"]]$venues$postalCode
    
  } else {
    
    target_df[row_number_last, 3] <- NA
    
  }
  
  if (!is.null(json_parsed_search_last[["_embedded"]]$venues$address$line1)) {
    
    target_df[row_number_last, 4] <- json_parsed_search_last[["_embedded"]]$venues$address$line1
    
  } else {
    
    target_df[row_number_last, 4] <- NA
    
  }
  
  if (!is.null(json_parsed_search_last[["_embedded"]]$venues$url)) {
    
    target_df[row_number_last, 5] <- json_parsed_search_last[["_embedded"]]$venues$url
    
  } else {
    
    target_df[row_number_last, 5] <- NA
    
  }
  
  if (!is.null(json_parsed_search_last[["_embedded"]]$venues$location$longitude)) {
    
    target_df[row_number_last, 6] <- as.double(json_parsed_search_last[["_embedded"]]$venues$location$longitude)
    
  } else {
    
    target_df[row_number_last, 6] <- NA
    
  }
  
  if (!is.null(json_parsed_search_last[["_embedded"]]$venues$location$latitude)) {
    
    target_df[row_number_last, 7] <- as.double(json_parsed_search_last[["_embedded"]]$venues$location$latitude)
    
  } else {
    
    target_df[row_number_last, 7] <- NA
    
  }

  return(
    list(data = target_df, status_check = check_success, meta = list(cases = n_entries,
                                                                     pages = n_pages,
                                                                     cases_per_page = per_page,
                                                                     last_page = last_page)))
  
}

```

The check of the status code vector reveals that all GET requests were successful. As expected, the resulting data frame contains more rows than the example data frame in the *Assignment Instructions* indicating that some venues have been added to the API since the PDF document was created.

```{r result_ex4, error = FALSE, warning = FALSE, message = FALSE}

call_DE <- ticketmaster_call(api_key, "DE")

sum(call_DE$status_check != 200)

venue_total_DE <- call_DE$data
glimpse(venue_total_DE)

```


## 5. Visualizing the extracted data

Some coordinates in the variables ``longitude`` and ``latitude`` lie way beyond the German borders and can be assumed to be faulty. For instance, there are `r nrow(venue_total_DE[venue_total_DE$latitude == 0.000000,])` cases with ``latitude`` equal to 0. Of course, this is impossible since Germany is not even close to the equator. Thus, these outliers are coded as NAs.

```{r plot_ex5, error = FALSE, warning = FALSE, message = FALSE}

venue_total_DE$longitude[venue_total_DE$longitude < 5.866944 | venue_total_DE$longitude > 15.043611] <- NA
venue_total_DE$latitude[venue_total_DE$latitude < 47.271679 | venue_total_DE$latitude > 55.0846] <- NA

plot_ex5_DE <- ggplot() +
  geom_polygon(aes(x = long, y = lat, group = group),
               data = map_data("world", region = "Germany"),
               fill = "grey90", color = "#D63D1C") +
  theme_void() +
  coord_quickmap() +
  labs(title = "Event locations across Germany", caption = "Source: ticketmaster.com") +
  theme(plot.title = element_text(hjust = 0.5, size = 10, face = "bold", colour = "black"),
        plot.caption = element_text(size = 8, face = "italic", colour = "#B0A505")) +
  geom_point(aes(x = longitude, y = latitude), data = venue_total_DE,
             alpha = 0.2, col = "#D63D1C")

plot_ex5_DE

```


## 6. Event locations in other countries {#ex6}

I decided to apply the same operations to the country of Sweden.

```{r venue_data_ex6, error = FALSE, warning = FALSE, message = FALSE}

get_search_result_ex6 <- GET("https://app.ticketmaster.com/discovery/v2/venues.json",
                         query = list(apikey = api_key,
                                      countryCode = "SE",
                                      locale = "*"))

json_parsed_search_ex6 <- fromJSON(content(get_search_result_ex6, as = "text"))

venue_data_ex6 <- data.frame(
  name = json_parsed_search_ex6[["_embedded"]]$venues$name,
  city = json_parsed_search_ex6[["_embedded"]]$venues$city$name,
  postalCode = json_parsed_search_ex6[["_embedded"]]$venues$postalCode,
  address = json_parsed_search_ex6[["_embedded"]]$venues$address$line1,
  url = json_parsed_search_ex6[["_embedded"]]$venues$url,
  longitude = as.double(json_parsed_search_ex6[["_embedded"]]$venues$location$longitude),
  latitude = as.double(json_parsed_search_ex6[["_embedded"]]$venues$location$latitude)
  )

glimpse(venue_data_ex6)

```

In order to extract all event locations I only had to change one parameter reaping the benefits from my clean code above.

```{r result_ex6, error = FALSE, warning = FALSE, message = FALSE}

call_SE <- ticketmaster_call(api_key, "SE")

sum(call_SE$status_check != 200)

venue_total_SE <- call_SE$data
glimpse(venue_total_SE)

```

I adjusted the colors to match the Swedish flag:

```{r plot_ex6, error = FALSE, warning = FALSE, message = FALSE}

venue_total_SE$longitude[venue_total_SE$longitude < 10.9575 | venue_total_SE$longitude > 24.155833] <- NA
venue_total_SE$latitude[venue_total_SE$latitude < 55.336944 | venue_total_SE$latitude > 69.06] <- NA

plot_ex6_SE <- ggplot() +
  geom_polygon(aes(x = long, y = lat, group = group),
               data = map_data("world", region = "Sweden"),
               fill = "#C5D0EB", color = "#0C39A7") +
  theme_void() +
  coord_quickmap() +
  labs(title = "Event locations across Sweden", caption = "Source: ticketmaster.com") +
  theme(plot.title = element_text(hjust = 0.5, size = 10, face = "bold", colour = "#0C39A7"),
        plot.caption = element_text(size = 8, face = "italic", colour = "#0C39A7")) +
  geom_point(aes(x = longitude, y = latitude), data = venue_total_SE,
             alpha = 0.2, col = "#F1F127")

plot_ex6_SE

```
